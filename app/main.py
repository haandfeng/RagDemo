# app/main.py
from pathlib import Path

from app.vectorstore import build_vectorstore_from_texts
from app.rag_chain import create_rag_chain
from app.config import config


# app/main.py ç‰‡æ®µ
from pathlib import Path

from app.vectorstore import build_vectorstore_from_texts
from app.rag_chain import create_rag_chain
from app.config import config


def ingest_demo_docs():
    """
    å¦‚æœ chroma_data å·²å­˜åœ¨ä¸”éç©ºï¼Œå°±è·³è¿‡é‡æ–° embeddingã€‚
    """
    chroma_dir = Path(config.vectorstore.persist_dir)

    if chroma_dir.exists() and any(chroma_dir.iterdir()):
        print(f"âœ… æ£€æµ‹åˆ°å·²å­˜åœ¨å‘é‡åº“ç›®å½•ï¼š{chroma_dir}ï¼Œè·³è¿‡é‡æ–° embeddingã€‚")
        return

    chroma_dir.mkdir(parents=True, exist_ok=True)

    # ğŸ”¹ è¿™é‡Œæ”¾ 6 æ®µé£æ ¼å·®å¼‚è¾ƒå¤§çš„æ–‡æ¡£ï¼Œæ–¹ä¾¿æµ‹è¯•æ£€ç´¢
    texts = [
        # 1. ç¡…åŸºæµåŠ¨
        "ç¡…åŸºæµåŠ¨ï¼ˆSiliconFlowï¼‰æ˜¯ä¸€å®¶æä¾›å¤§æ¨¡å‹æ¨ç†æœåŠ¡çš„å…¬å¸ï¼Œ"
        "å…¶å¹³å°å…¼å®¹ OpenAI æ¥å£ï¼Œç”¨æˆ·å¯ä»¥ç”¨ç›¸åŒçš„ SDK å’Œåè®®è°ƒç”¨åŒ…æ‹¬ Qwen åœ¨å†…çš„å¤šç§ä¸­æ–‡æ¨¡å‹ã€‚",

        # 2. Qwen3-8B å¯¹è¯æ¨¡å‹
        "Qwen3-8B æ˜¯é€šä¹‰åƒé—®ç³»åˆ—ä¸­çš„ä¸€æ¬¾ä¸­ç­‰è§„æ¨¡å¼€æºæ¨¡å‹ï¼Œé€‚åˆåšå¯¹è¯ã€ä»£ç ç¼–å†™å’ŒåŸºç¡€é—®ç­”ç­‰ä»»åŠ¡ï¼Œ"
        "åœ¨ä¸­æ–‡åœºæ™¯ä¸‹æœ‰è¾ƒå¥½çš„æ•ˆæœï¼Œå¸¸æ­é… RAG æ–¹æ¡ˆä½¿ç”¨ã€‚",

        # 3. BAAI/bge-m3 å‘é‡æ¨¡å‹
        "BAAI/bge-m3 æ˜¯æ™ºè°±å’ŒåŒ—äº¬æ™ºæºå‘å¸ƒçš„å¤šè¯­è¨€é€šç”¨å‘é‡æ¨¡å‹ï¼Œ"
        "æ”¯æŒä¸­æ–‡ã€è‹±æ–‡ç­‰å¤šç§è¯­è¨€ï¼Œå¸¸ç”¨äºè¯­ä¹‰æ£€ç´¢ã€RAGã€é‡æ’åºç­‰åœºæ™¯ã€‚",

        # 4. RAG ä»‹ç»
        "RAGï¼ˆRetrieval-Augmented Generationï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ˜¯ä¸€ç§ç»“åˆå‘é‡æ£€ç´¢ä¸å¤§æ¨¡å‹ç”Ÿæˆçš„æŠ€æœ¯æ–¹æ¡ˆï¼Œ"
        "å®ƒé€šè¿‡å…ˆä»å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼Œå†æŠŠæ–‡æ¡£å’Œé—®é¢˜ä¸€èµ·å–‚ç»™å¤§æ¨¡å‹ï¼Œä»è€Œå‡å°‘å¹»è§‰ã€å¢å¼ºå¯¹çŸ¥è¯†åº“çš„åˆ©ç”¨ã€‚",

        # 5. Python + LangChain å¼€å‘
        "åœ¨ Python ä¸­å¯ä»¥ä½¿ç”¨ LangChain å¿«é€Ÿæ­å»º RAG åº”ç”¨ï¼Œ"
        "æ¯”å¦‚ä½¿ç”¨ Chroma ä½œä¸ºæœ¬åœ°å‘é‡åº“ã€OpenAIEmbeddings ä½œä¸º embedding å°è£…ã€ChatOpenAI ä½œä¸ºå¯¹è¯æ¨¡å‹å°è£…ã€‚",

        # 6. å®Œå…¨ä¸ç›¸å…³çš„æ—…æ¸¸æ®µè½
        "æ—¥æœ¬äº¬éƒ½æ˜¯ä¸€åº§å†å²æ‚ ä¹…çš„åŸå¸‚ï¼Œæ‹¥æœ‰æ¸…æ°´å¯ºã€é‡‘é˜å¯ºç­‰ä¸–ç•Œæ–‡åŒ–é—äº§ã€‚"
        "æ˜¥å¤©å¯ä»¥èµæ¨±ï¼Œç§‹å¤©å¯ä»¥è§‚çº¢å¶ï¼Œæ˜¯éå¸¸çƒ­é—¨çš„æ—…æ¸¸ç›®çš„åœ°ã€‚",
    ]
    metadatas = [
        {"source": "siliconflow_intro"},
        {"source": "qwen3_8b_intro"},
        {"source": "bge_m3_intro"},
        {"source": "rag_intro"},
        {"source": "python_langchain_intro"},
        {"source": "kyoto_travel"},
    ]

    build_vectorstore_from_texts(texts, metadatas)
    print(f"âœ… å·²å®Œæˆç¤ºä¾‹æ–‡æ¡£å‘é‡åŒ–å¹¶å†™å…¥ Chromaï¼š{chroma_dir}\n")


def interactive_chat():
    rag_chain = create_rag_chain()

    print("RAG Debug Demo å·²å¯åŠ¨ï¼Œè¾“å…¥é—®é¢˜å¼€å§‹å¯¹è¯ï¼Œè¾“å…¥ `exit` é€€å‡ºã€‚")
    while True:
        question = input("\nç”¨æˆ·: ").strip()
        if not question:
            continue
        if question.lower() in {"exit", "quit"}:
            break

        try:
            # DebugRAGChain.invoke å†…éƒ¨ä¼šæ‰“å°æ£€ç´¢ / Prompt / ç­‰å¾… / å›å¤
            answer = rag_chain.invoke(question)

            print("\n====== æœ€ç»ˆå›ç­”ï¼ˆæ•´ç†åç»™ç”¨æˆ·ï¼‰ ======")
            print(answer)
            print("====================================\n")
        except Exception as e:
            print(f"å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    ingest_demo_docs()
    interactive_chat()